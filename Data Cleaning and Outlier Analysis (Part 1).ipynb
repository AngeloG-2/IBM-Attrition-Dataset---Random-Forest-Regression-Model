{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34f47cd3",
   "metadata": {},
   "source": [
    "<font size=\"5\" >PURPOSE OF PROJECT: CREATE A REGRESSION MODEL TO PREDICT MONTHLY INCOME </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc8437",
   "metadata": {},
   "source": [
    "<font size=\"4\"> My project is split into 3 parts. Each notebook focuses on a specific portion of the machine learning workflow. This notebook is part 1 out of 3 of my Regression Model Project. </font>\n",
    "    \n",
    "<font size=\"4\"> The focus in this notebook are data cleaning and outlier analysis. See part 2 and part 3 for notebooks on feature selection and model performance evaluation.  </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "913e9873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60801538",
   "metadata": {},
   "source": [
    "# OUTLIER ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063daf3e",
   "metadata": {},
   "source": [
    "The purpose of outlier analysis is to determine if dropping rows with outliers is ideal or not.\n",
    "\n",
    "CONCLUSION:\n",
    "\n",
    "1. 47% of rows in the dataset will be dropped. This is too many rows and removing outliers will lead to information loss.\n",
    "2. The model we are using, Random Forest, is NOT sensitive to outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19e54c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('ibm_attrition_group_version_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34db24c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "obtain all numeric columns for outlier analysis.\n",
    "'''\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df_num = df.select_dtypes(include=numerics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efc3bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "691\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Compute number of rows to be dropped. \n",
    "\n",
    "STEPS PERFORMED BY THE ALGORITHM:\n",
    "\n",
    "1. This code gets the row numbers of outliers in each column. To detect outliers, a boxplot is used.\n",
    "\n",
    "2. Append the row number of outliers in each column in a 2d array.\n",
    "    \n",
    "    For example: [5,7,13,18] append -> [[1,5,7],[3,6,9]] -> [[1,5,7],[3,6,9],[5,7,13,18]]\n",
    "    \n",
    "    NOTE: Each list in the 2d array represents the row numbers of outliers i n one column. \n",
    "          So if you have n columns, you will have n lists inside the 2d array.\n",
    "\n",
    "3. To determine the total number of rows to be dropped, a set union is operation is \n",
    "   applied to each list inside 2d array. This gets all the unique values in the all nested lists and removes duplicates.\n",
    "\n",
    "    For Example: [[1,2,3],[1,2,7]] the result after the union operation is {1,2,3,7}\n",
    "    \n",
    "4. The set computed in step 3 will contain the unique row numbers which will be dropped. \n",
    "   The length of this set is the number of rows to be dropped.\n",
    "\n",
    "691 rows will be dropped.\n",
    "\n",
    "47% of rows will be dropped.\n",
    "'''\n",
    "\n",
    "row_list = []\n",
    "\n",
    "for col in df_num.columns:\n",
    "    \n",
    "    q3 = df_num[col].quantile(0.75)\n",
    "    q1 = df_num[col].quantile(0.25)\n",
    "\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    col_outliers = df_num[((df_num[col] > (q3 + iqr*1.5)) | (df_num[col] < (q1 - iqr*1.5)))]\n",
    "    row_list.append(col_outliers['Unnamed: 0'].values)\n",
    "    \n",
    "print(len(list(set().union(*row_list))))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4495ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Unnamed: 0': 0,\n",
       " 'Age': 0,\n",
       " 'DailyRate': 0,\n",
       " 'DistanceFromHome': 0,\n",
       " 'Education': 0,\n",
       " 'EmployeeNumber': 0,\n",
       " 'EnvironmentSatisfaction': 0,\n",
       " 'HourlyRate': 0,\n",
       " 'JobInvolvement': 0,\n",
       " 'JobLevel': 0,\n",
       " 'JobSatisfaction': 0,\n",
       " 'MonthlyIncome': 114,\n",
       " 'MonthlyRate': 0,\n",
       " 'NumCompaniesWorked': 52,\n",
       " 'PercentSalaryHike': 0,\n",
       " 'PerformanceRating': 226,\n",
       " 'RelationshipSatisfaction': 0,\n",
       " 'StockOptionLevel': 85,\n",
       " 'TotalWorkingYears': 63,\n",
       " 'TrainingTimesLastYear': 238,\n",
       " 'WorkLifeBalance': 0,\n",
       " 'YearsAtCompany': 104,\n",
       " 'YearsInCurrentRole': 21,\n",
       " 'YearsSinceLastPromotion': 107,\n",
       " 'YearsWithCurrManager': 14}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Calculate the number of outliers for each column\n",
    "\n",
    "This algorithm filters rows with outliers based on a single column. Then the algorithm computes \n",
    "the length of the filtered dataframe, which corresponds to the number of rows. Then the results are stored in\n",
    "dictionary, where keys are columns names and values, is the number of outliers.\n",
    "'''\n",
    "\n",
    "d = {}\n",
    "\n",
    "for col in df_num.columns:\n",
    "    \n",
    "    q3 = df_num[col].quantile(0.75)\n",
    "    q1 = df_num[col].quantile(0.25)\n",
    "\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    col_outliers = df_num[((df_num[col] > (q3 + iqr*1.5)) | (df_num[col] < (q1 - iqr*1.5)))]\n",
    "    d[col] = len(col_outliers)\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937347eb",
   "metadata": {},
   "source": [
    "# GENERAL DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cb00466",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Angelo Gaerlan\\Desktop\\Courses\\Npower stuff\\JDA Npower model project\\WA_Fn-UseC_-HR-Employee-Attrition.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d974ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 43,\n",
       " 'Attrition': 2,\n",
       " 'BusinessTravel': 3,\n",
       " 'DailyRate': 886,\n",
       " 'Department': 3,\n",
       " 'DistanceFromHome': 29,\n",
       " 'Education': 5,\n",
       " 'EducationField': 6,\n",
       " 'EmployeeCount': 1,\n",
       " 'EmployeeNumber': 1470,\n",
       " 'EnvironmentSatisfaction': 4,\n",
       " 'Gender': 2,\n",
       " 'HourlyRate': 71,\n",
       " 'JobInvolvement': 4,\n",
       " 'JobLevel': 5,\n",
       " 'JobRole': 9,\n",
       " 'JobSatisfaction': 4,\n",
       " 'MaritalStatus': 3,\n",
       " 'MonthlyIncome': 1349,\n",
       " 'MonthlyRate': 1427,\n",
       " 'NumCompaniesWorked': 10,\n",
       " 'Over18': 1,\n",
       " 'OverTime': 2,\n",
       " 'PercentSalaryHike': 15,\n",
       " 'PerformanceRating': 2,\n",
       " 'RelationshipSatisfaction': 4,\n",
       " 'StandardHours': 1,\n",
       " 'StockOptionLevel': 4,\n",
       " 'TotalWorkingYears': 40,\n",
       " 'TrainingTimesLastYear': 7,\n",
       " 'WorkLifeBalance': 4,\n",
       " 'YearsAtCompany': 37,\n",
       " 'YearsInCurrentRole': 19,\n",
       " 'YearsSinceLastPromotion': 16,\n",
       " 'YearsWithCurrManager': 18}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Check for constant columns.\n",
    "\n",
    "If the length of the value_counts() for a specific feature == 1, there is only 1 unique values in that column; therefore, \n",
    "the column is non-chnaging.\n",
    "\n",
    "Non-changing columns will be dropped.\n",
    "\n",
    "THE FOLLOWING ARE NON-CHANGING COLUMNS:\n",
    "\n",
    "1. EmployeeCount\n",
    "2. Over18\n",
    "3. StandardHours\n",
    "'''\n",
    "\n",
    "d = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    d[col] = len(df[col].value_counts())\n",
    "\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d7c83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "drop all constant columns\n",
    "'''\n",
    "\n",
    "df.drop(columns=['EmployeeCount','Over18','StandardHours'],inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c7d3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Attrition',\n",
       " 'BusinessTravel',\n",
       " 'Department',\n",
       " 'EducationField',\n",
       " 'Gender',\n",
       " 'JobRole',\n",
       " 'MaritalStatus',\n",
       " 'OverTime'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "get all categorical columns\n",
    "'''\n",
    "\n",
    "categorical_cols = set(df._get_numeric_data().columns).symmetric_difference(set(df.columns))\n",
    "\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e41e12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convert all categorical columns into lower case. \n",
    "\n",
    "This ensures that strings can be grouped together with aggregate functions or filtered effectively.\n",
    "'''\n",
    "\n",
    "for cat_column in categorical_cols:\n",
    "    df[cat_column] = df[cat_column].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2f6acc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         0\n",
       "Attrition                   0\n",
       "BusinessTravel              0\n",
       "DailyRate                   0\n",
       "Department                  0\n",
       "DistanceFromHome            0\n",
       "Education                   0\n",
       "EducationField              0\n",
       "EmployeeNumber              0\n",
       "EnvironmentSatisfaction     0\n",
       "Gender                      0\n",
       "HourlyRate                  0\n",
       "JobInvolvement              0\n",
       "JobLevel                    0\n",
       "JobRole                     0\n",
       "JobSatisfaction             0\n",
       "MaritalStatus               0\n",
       "MonthlyIncome               0\n",
       "MonthlyRate                 0\n",
       "NumCompaniesWorked          0\n",
       "OverTime                    0\n",
       "PercentSalaryHike           0\n",
       "PerformanceRating           0\n",
       "RelationshipSatisfaction    0\n",
       "StockOptionLevel            0\n",
       "TotalWorkingYears           0\n",
       "TrainingTimesLastYear       0\n",
       "WorkLifeBalance             0\n",
       "YearsAtCompany              0\n",
       "YearsInCurrentRole          0\n",
       "YearsSinceLastPromotion     0\n",
       "YearsWithCurrManager        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Check if dataframe has missing values.\n",
    "\n",
    "NOTE: There are no missing values.\n",
    "'''\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb404cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Check if the IBM dataset has any duplicate rows.\n",
    "\n",
    "Since the dataframe with duplicates dropped has the same length as the orginal dataframe, there are no duplicate rows \n",
    "in the dataset\n",
    "'''\n",
    "len(df.drop_duplicates()) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "670f28b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Save the cleaned dataset into a CSV \n",
    "'''\n",
    "\n",
    "df.to_csv('ibm_attrition_group_version_1.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
